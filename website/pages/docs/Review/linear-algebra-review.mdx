---
title: Linear Algebra Review
section: Review
order: 1
---

import Katex from "../../../components/Katex";

# Review of Linear Algebra

Definition:

## Matrices


<Katex>{`
A $$m \\times n$$ matrix is a rectuangular array with m rows and n columns:
$$
    \\mathbf{A} = (a_{ij})_{m \\times n} = \\begin{pmatrix}
        a_{11} & a_{12} & \\dots & a_{1n} \\newline
        a_{21} & a_{22} & \\dots & a_{2n} \\newline
        \\vdots & \\vdots &  \\ddots & \\vdots \\newline
        a_{m1} & a_{m2} & \\dots & a_{mn} 
    \\end{pmatrix}
$$
Above we have $$m \\times n$$ individual entries, each of which can be identified by $$a_{ij}$$ where i is the row and j is the column it is located in.
`}</Katex>


### Property of Matrices

<Katex>{`
$$
\\begin{align}
   (AB)C &= A(BC) \\newline
   A(B+ C) &= AB + AC  & \\text{left distributive law} \\newline
   (A + B)C &= AC + BC  & \\text{right distributive law} \\newline 
   AB & \\neq BA   & \\text{except in special cases} \\newline 
   AB = 0 & \\quad & \\text{does not imply that } A or B  is 0 \\newline
   AB = AC & \\quad \\text{and} \\quad  A \\neq 0 & \\text{do not imply that } B = C
\\end{align}
$$
`}</Katex>

### Identiy matrix

<Katex>{`
The identity matrix of order $$n $$ is denoted by $$\\mathbf{I_n}$$ or often just $$\\mathbf{I}$$ and it is the $$ n \\times n$$ matrix having ones along the main diagonal and zeros elsewhere:
$$
\\mathbf{I}_n = \\begin{pmatrix} 
1 & 0 & \\dots & 0 \\newline
0 & 1 & \\dots & 0 \\newline 
\\vdots & \\vdots & \\ddots & \\vdots \\newline 
0 & 0 & \\dots & 1 
\\end{pmatrix}
$$
`}</Katex>

### Transpose 
<Katex>{`
The transpose of a matrix is commonly written: $$\\mathbf{A} '$$ or $$\\mathbf{A}^T$$. For ease of viewing on a browser, these notes will use: $$\\mathbf{A}^T$$
If $$\\mathbf{A} = (a_{ij})_{m \\times n}$$ is a matrix, then the transpose is: 
$$
\\mathbf{A}^T = (A_{ji})_{n_\\times n}
$$
`}</Katex>

#### Properties of Tranpose:

<Katex>{`
$$
\\begin{align}
& (\\mathbf{A^T})^T = \\mathbf{A} \\newline
& (\\mathbf{A} + \\mathbf{B})^T = \\mathbf{A}^T + \\mathbf{B}^T  \\newline 
& (\\alpha \\mathbf{A})^T = \\alpha \\mathbf{A}^T \\newline 
& (\\mathbf{AB})^T = \\mathbf{B}^T \\mathbf{A}^T
\\end{align}
$$
`}</Katex>

### Symmetric Matrices: 
<Katex>{`
A square matrix is called symmetric if 
$$ \\mathbf{A} = \\mathbf{A}^T $$
`}</Katex>

## Determinants 

<Katex>{`
$$ 
| \\mathbf{A} | = \\begin{vmatrix}
a_{11} & a_{12} \\newline 
a_{21} & a_{22} 
\\end{vmatrix} = a_{11} a_{22} - a_{21} a_{12} 
$$
`}</Katex>

Find A WAY TO WRITE THE COOL DETERMINANT TRICK IN HERE SOME HOW 
To generalize the determinant, the easiest way is usually looking at the cofactors of the matrix and recursively calculating the determinant. Computers can be incredibly quick at this. 

### Manipulating determinants 
The following rules are for Manipulating determinants:
  
1. If two rows or columns of **A** are interchanged, the determinant changes sign but its absolute value remains unchanged.
2. If all elements in a single row or column of **A** are multiplied by a skalar, the determinant is multiplied by the same scalar.
3. If two of the rows or columns of **A** are porportional, then the determinant is 0. 
4. The value of the determinant remains unchanged if a multiple of one row (or one column) is added to another row or column 

### Properties of determinants 
<Katex>{`
$$ 
\\begin{align}
& | \\mathbf{A}^T  | = | \\mathbf{A} | \\newline 
& | \\mathbf{AB} | = | \\mathbf{A} | \\cdot |\\mathbf{B} | \\newline 
& | \\mathbf{A + B } | \\neq |\\mathbf{A}| + |\\mathbf{B}| \\quad \\text{usually} 
\\end{align}
$$
`}</Katex>

## Inverse 

<Katex>{`
The inverse $$\\mathbf{A}^{-1}$$ of an $$n \\times n$$ matrix is defined such that is satisfies the following:
$$ 
\\mathbf{B = A}^{-1} \\iff \\mathbf{AB} = \\mathbf{I}_n \\iff \\mathbf{BA} = \\mathbf{I}_n 
$$
From this, it follow that : 
$$
\\mathbf{A}^{-1} \\quad \\text{exists} \\iff | \\mathbf{A} | \\neq 0 
`}</Katex>

**ADD FORMULA 28 NOT SURE WHAT IT MEANS**

In particular, memorizing the formula for a 2 x 2 matrix can be very helpful: 

<Katex>{`
$$ 
\\begin{pmatrix}
a & b \\newline
c & d 
\\end{pmatrix}^{-1} = \\frac{1}{ad - bc} \\begin{pmatrix} 
d & -b \\newline 
-c & a 
\\end{pmatrix} \\quad \\text{if} \\quad \\begin{vmatrix} 
a & b \\newline 
c & d 
\\end{vmatrix} = ad - bc \\neq 0 
$$
`}</Katex>

### Properties of Inverse  
<Katex>{`
$$ 
\\begin{align}
& (\\mathbf{A}^{-1})^{-1} = \\mathbf{A} \\newline 
& (\\mathbf{AB}^{-1}) = \\mathbf{B^{-1}A^{-1}} \\newline 
& (\\mathbf{A}^T)^{-1} = (\\mathbf{A}^{-1})^T \\newline 
& (k \\mathbf{A})^{-1} = k^{-1} \\mathbf{A}^{-1} 
\\end{align}
$$
`}</Katex>

## Cramer's Rule 
Consider a system of n equations with n unknowns. The system has a unique solution if and only if the determinant is non zero. That is:
<Katex>{`
$$ 
| \\mathbf{A} | = |(a_{ij})_{n \\times n} | \\neq 0 
$$
and the unique solution is then: 
$$
x_j | \\mathbf{A}_j / |\\mathbf{A}|, \\quad j = 1,2, \\dots , n 
$$ 
where $$| \\mathbf{A_j}| $$ denotes the determinant of $$ \\mathbf{A} $$ with is jth column replaced by the column with components $$b_1, b_2, \\dots , b_n$$ 
`}</Katex>

### Homogenous system 
A homogenous is a system of equations that can be written in matrix form as:
<Katex>{`
$$ 
\\mathbf{Ax = 0}
$$
A homogenous system will always have the trivial solution where all $$x_i$$ = 0. From this, the square matrix **A** in $$Ax = 0$$ has non trivial solutions $$\\iff | \\mathbf{A} | = 0 $$
`}</Katex>


## Vectors 

### Properties of vectors 

<Katex>{`
$$ 
\\begin{align}
& \\mathbf{a \\cdot b} = \\mathbf{b \\cdot a } \\newline 
& \\mathbf{a} \\cdot  \\mathbf{(b + c)} = \\mathbf{a} \\cdot \\mathbf{b + a} \\cdot c \\newline 
& ( \\alpha \\mathbf{a}) \\cdot \\mathbf{b = a \\cdot }(\\alpha \\mathbf{b}) = \\alpha (\\mathbf{a \\cdot b})
\\end{align}
$$
`}</Katex>


### Euclidean norm or length of a vector is: 
<Katex>{`
$$ 
|| \\mathbf{a} ||  = \\sqrt{\\mathbf{a \\cdot a }} = \\sqrt{a_1^2 + a_2^2 + \\dots + a_n^2}
$$
`}</Katex>

<Katex>{`
Note that $$|| \\alpha \\mathbf{a} || = | \\alpha | \\cdot  || \\mathbf{a} || $$ for all scalars and vectors. 
`}</Katex>

### Important inequalities

#### Cauchy-Schwarz inequality 
The cauchy-schwarz inequality states that for all vectors of an inner product space it is true that:
<Katex>{`
$$ 
|\\mathbf{a \\cdot b} | \\leq \\mathbf{||a || \\cdot ||b||}
$$
`}</Katex>

#### Triangle Inequality for vector norms 
In simple geometric terms, this shows that for any triangle, the sum of the lengths of any two sides must be greater than or equal to the remaining side. 
<Katex>{`
$$ 
||\\mathbf{a + b }|| \\leq \\mathbf{||a|| + ||b|| }
$$
`}</Katex>



<Katex>{`
$$ 
placeholder 
$$
`}</Katex>






## Previous 

The rank of A is the maximum number of linearly independent column vectors of A. The rank of the zero matrix is 0. 

Example:
<Katex>{`
$$
A = (A_ij)_{n \\times n} \\Rightarrow r(A) \\leq n \\quad \\text{and} \\quad r(A) = n 
$$
The determinant must therefore be non-zero. The columns are all linearly independent, if and only if, there is a non-zero determinant and therefore it must be a square matrix. 
`}</Katex>

### Minor of order k:
Determinant of submatrix of A obtained by deleting all but k rows and k columns. 

Minor of order 1 is just an individual element. 

For example:

<Katex>{`
A quadratic form $$ Q(\\mathbf{x}) = \\mathbf{x'Ax} $$ as well as its associated symmetric matrix $$ \\mathbf{A} $$  are said to be:
`}</Katex>

<Katex>{`
$$ 
\\begin{pmatrix}
1 & 2 & 2 & 1 \\newline
0 & 2 & 4 & 2 \\newline
0 & 2 & 2 & 1
\\end{pmatrix}
$$
`}</Katex>

In the above, we have
- 4 minors of order 3
- 18 minors of order 2
- 12 minors of order 1 (individual elements)

<Katex>{`
An $$m \\times n$$ matrix has $$ {f \\choose k} {m \\choose k}  $$ minors of order k. For example, the above has  THIS IS MISSING STUFF 
$$
{n \\choose k} {n \\choose k}
$$
`}</Katex>



<Katex>{`
In general: 
$$  = \\frac{m!}{k! (n-k)!} \\cdot \\frac{n!}{k! (n-k)!}$$ This is missing stuff
`}</Katex>





<Katex>{`
Theorem: The rank $$r(\\mathbf{A})$$ of matrix **A** is equal to the order of the largest minor of A that is non-zero. 
`}</Katex>



Any system of linear equations can be written as a vector equation of the form:


<Katex>{`
$$
x_1 a_1 + x_2 a_2 + x_3 a_3 ... = b
$$
`}</Katex>


In the above equation:


Theorem 1.4.2: 
In essence it doesn't matter whether you work with rows or columns. The result will be the same. 






This is a place to review all the critical components of linear algebra.

## Quadratic Forms
<Katex>{`
A quadratic form in $$ n $$ variables is a function $$ Q $$ of the form:
$$
Q(x_1, \\dots , x_n) = \\sum_{i = 1}^n \\sum_{j = 1}^n a_{ij}x_i x_j
$$
where $a_{ij}$ are constants. Suppose we put $\\mathbf{x} = (x_1, x_2, \\dots , x_n)'$ and $\\mathbf{A} = (a_{ij})$. Then it follows: 
$$
Q(x_1, \\dots , x_n)
$$
In other words, a quadratic form is a homogenous degree 2 polynomial in $n$ variables. Homogenous meaning that all are of the same degree, so you can scale the variabels and the entire function scales similarly. In 2 varaibles we  have:
$$
Q(x_1, x_{21}) = SOMETHING HERE
$$ 
`}</Katex>

### Definiteness of a quadratic form

<Katex>{`
A quadratic form $Q(\\mathbf{x}) = \\mathbf{x'Ax}$ as well as its associated symmetric matrix $$ \\mathbf{A} $$  are said to be:
`}</Katex>

- positive semi-definite
- negative semi-definite
- positive definite
- negative definite
- indefinite

Theorem:

<Katex>{`
1) Positive semidefinite $ \\iff a_{11}, a_{22} \\geq 0 $ and $a_{11, a_{22} \\geq a_{12}^2}$ (with notation of matrix $ \\mathbf{A} $)
2) Negative semidefinite $\\iff$
3) Positive definite $\\iff$
4) Negative definite $\\iff$
There is a relationship between them as well. Insert explanation. Insert examples here as well. 
`}</Katex>

#### General Case:

<Katex>{`
$$
Q(x_1, \\dots , x_n) = \\sum_{i= 1}^n \\sum_{j = 1}^n a_{ij}x_i x_j = t \\begin{pmatrix} 
x_1 \\newline
\\vdots \\newline
x_3
\\end{pmatrix} (a_{ij})_{n \\times n} \\begin{pmatrix}
x_1 \\newline
\\vdots  \\newline
x_n 
\\end{pmatrix}
$$
Note above: $$ (a_{ij} = a_{ji}) $$
The form itself, $ Q $, can be rewritten to make the matrix  $ A $ representing it symmetric. How is this not working. Wow. Now?
Principal minor of order $k$: minor of order $k$ such taht if the $i$-th row is picked, the so is the $i$-th column (denoted by $\\Delta_k$)
`}</Katex>

Leading Principal Minor!

<Katex>{`
If the symmetric matrix $$A = (a_{ij})_{n \\times n} $$ represents the quadratic form $$ Q(x) = x^t A x $$, then $Q$ is:
1) **Positive definite** (values always positive with non zero axes) $ \\iff D_k > 0 \\quad  \\forall 1 \\leq k \\leq n $
2) **Positive semidefinite** $ \\iff \\Delta_k \\geq 0 \\quad \\forall k, \\forall $ principal minors of order $k$. 
3) **Negative definite:** $ \\iff (-1)^k D_k > 0 \\quad \\forall 1 \\leq k \\leq n $
4) **Negative semidefinite:** $ \\iff (-1)^k \\Delta_k \\geq 0 \\quad \\forall \\, k $ and for all principal minors of order $k$
`}</Katex>

Example:
<Katex>{`
$$ 3x_1^2 +6x_1 x_3 + x_2^2 - 4x_2 x_3 + 8x_3^2$$
This translates into:
$$
A = \\begin{pmatrix}
3 & 0 & 3 \\newline
0 & 1 & -2 \\newline
3 & -2 & 8
\\end{pmatrix}
$$
So what are all the leading principal minors. We have three: just the top left entry, 3, the top 2 by 2 matrix $$ \\begin{pmatrix} 3 & 0 \\newline 0 & 1 \\end{pmatrix} $$, and the entire matrix. 
The determinent for all 3 of these are 3, so the result is positive definite. 
`}</Katex>

Second example:
<Katex>{`
$$
-x_1^2 + 6x_1x_2 - 9 x_2^2 - 2x_3^2 
$$
Which translates into:
$$ 
\\begin{pmatrix}
-1 & 3 & 0 \\newline
3 & -9 & 0 \\newline
0 & 0 & -2
\\end{pmatrix}
$$
This in a sense is a more trivial case as the original case is a square. You can translate it into: $$ - (x_1  + 3x_2)^2 -2x_3^2 $$ which is obviously negative semidefinite. 
`}</Katex>

#### Eigenvalues approach to determining definiteness. 
Theorem:

<Katex>{`
Let $Q = \\mathbf{x'Ax}$ be a quadratic form where A is the symmetric matrix and $\\lambda_1,\\dots, \\lambda_n $ are the (real because it is symmetric) eigenvalues of $\\mathbf{A}$, then: $Q$ is:
1) Positive definite $\\iff \\lambda_i > 0 \\quad \\forall i $
2) Positive semidefinite $\\iff \\lambda_i \\geq 0$
3) Negative definite $\\iff \\lambda_i < 0$
4) Negative semidefinite $\\iff \\lambda_i \\leq 0$
5) **Indefinite** $\\iff \\mathbf{A}$ eigenvalues with opposite signs 
`}</Katex>

Example goes here.

Example 4. 



Before adding file Still working? 

<Katex>{`
Example
`}</Katex>
